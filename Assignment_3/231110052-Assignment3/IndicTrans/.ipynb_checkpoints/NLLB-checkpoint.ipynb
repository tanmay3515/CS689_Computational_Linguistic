{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vwNA2m2y_FvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in /Users/tanmaydubey/anaconda3/lib/python3.11/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: six in /Users/tanmaydubey/anaconda3/lib/python3.11/site-packages (from rouge) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MhL0hSCwZ6kp"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def select_and_save_random_sentences(english_file, hindi_file, gujarati_file, num_sentences=5):\n",
    "\n",
    "    # Read all sentences from each file\n",
    "    with open(english_file, \"r\") as f:\n",
    "        english_sentences = f.readlines()\n",
    "    with open(hindi_file, \"r\") as f:\n",
    "        hindi_sentences = f.readlines()\n",
    "    with open(gujarati_file, \"r\") as f:\n",
    "        gujarati_sentences = f.readlines()\n",
    "\n",
    "  # Ensure all files have the same number of sentences\n",
    "    if len(english_sentences) != len(hindi_sentences) or len(english_sentences) != len(gujarati_sentences):\n",
    "        raise ValueError(\"All files must have the same number of sentences\")\n",
    "\n",
    "  # Select random sentences (use set to avoid duplicates)\n",
    "    selected_indices = random.sample(range(len(english_sentences)), num_sentences)\n",
    "\n",
    "  # Create lists to store selected sentences with newlines\n",
    "    selected_english = []\n",
    "    selected_hindi = []\n",
    "    selected_gujarati = []\n",
    "\n",
    "  # Extract selected sentences from each list and add newlines\n",
    "    for index in selected_indices:\n",
    "        selected_english.append(english_sentences[index].strip())\n",
    "        selected_hindi.append(hindi_sentences[index].strip())\n",
    "        selected_gujarati.append(gujarati_sentences[index].strip())\n",
    "    return(selected_english, selected_hindi, selected_gujarati)\n",
    "    print(f\"Successfully selected and saved {num_sentences} random sentences from each file (each sentence on a new line).\")\n",
    "\n",
    "# Replace with your actual file paths\n",
    "english_file = \"test.en\"\n",
    "hindi_file = \"test.hi\"\n",
    "gujarati_file = \"test.gu\"\n",
    "\n",
    "en, hi, gu = select_and_save_random_sentences(english_file, hindi_file, gujarati_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dj7r_q_1XybG"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "\n",
    "def translate(lang, l):\n",
    "  a = []\n",
    "  for i in range(len(l)):\n",
    "    inputs = tokenizer(l[i], return_tensors=\"pt\")\n",
    "\n",
    "    translated_tokens = model.generate(\n",
    "        **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[lang], max_length=30\n",
    "    )\n",
    "    a.append(tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0])\n",
    "  return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OaOVuH-CE84j"
   },
   "outputs": [],
   "source": [
    "hin = \"hin_Deva\"\n",
    "eng = \"eng_Latn\"\n",
    "guj = \"guj_Gujr\"\n",
    "en_hi = translate(hin, en)\n",
    "hi_en = translate(eng, hi)\n",
    "hi_gu = translate(guj, hi)\n",
    "gu_hi = translate(hin, gu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8d288e2s58N4"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "from rouge import Rouge\n",
    "\n",
    "def calculate_scores(references, hypotheses):\n",
    "    # Calculate BLEU score\n",
    "    bleu_score = corpus_bleu([[ref] for ref in references], hypotheses)\n",
    "\n",
    "    # Initialize rouge scorer\n",
    "    rouge = Rouge()\n",
    "\n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = rouge.get_scores(hypotheses, references, avg=True)\n",
    "\n",
    "    return bleu_score, rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3htvkUvw5-YN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU, ROUGE scores of en_hi 0.6780296262972747 {'rouge-1': {'r': 0.5818939393939393, 'p': 0.6337556561085972, 'f': 0.6031457496936823}, 'rouge-2': {'r': 0.35884920634920636, 'p': 0.381905744754042, 'f': 0.36872053374864844}, 'rouge-l': {'r': 0.5518939393939395, 'p': 0.5984615384615385, 'f': 0.57071331726125}}\n",
      "BLEU, ROUGE scores of hi_en 0.7227394339376957 {'rouge-1': {'r': 0.6662745098039216, 'p': 0.6110079119367045, 'f': 0.6347054357794892}, 'rouge-2': {'r': 0.36921568627450985, 'p': 0.35804953560371516, 'f': 0.3633147813782457}, 'rouge-l': {'r': 0.6662745098039216, 'p': 0.6110079119367045, 'f': 0.6347054357794892}}\n",
      "BLEU, ROUGE scores of hi_gu 0.5666891869662894 {'rouge-1': {'r': 0.4813888888888888, 'p': 0.5165418894830659, 'f': 0.494095700664276}, 'rouge-2': {'r': 0.27305764411027567, 'p': 0.28059829059829056, 'f': 0.27429691382786076}, 'rouge-l': {'r': 0.40694444444444444, 'p': 0.4412477718360071, 'f': 0.4195580050739488}}\n",
      "BLEU, ROUGE scores of gu_hi 0.6586831835575037 {'rouge-1': {'r': 0.5849242424242425, 'p': 0.5753968253968254, 'f': 0.5762897215651973}, 'rouge-2': {'r': 0.33615079365079364, 'p': 0.34180721239544765, 'f': 0.33647907151188694}, 'rouge-l': {'r': 0.5149242424242424, 'p': 0.5134920634920634, 'f': 0.5106577925186342}}\n"
     ]
    }
   ],
   "source": [
    "BLEU_en_hi, ROUGE_en_hi = calculate_scores(hi, en_hi)\n",
    "BLEU_hi_en, ROUGE_hi_en = calculate_scores(en, hi_en)\n",
    "BLEU_hi_gu, ROUGE_hi_gu = calculate_scores(gu, hi_gu)\n",
    "BLEU_gu_hi, ROUGE_gu_hi = calculate_scores(hi, gu_hi)\n",
    "print(\"BLEU, ROUGE scores of en_hi\", BLEU_en_hi, ROUGE_en_hi)\n",
    "print(\"BLEU, ROUGE scores of hi_en\", BLEU_hi_en, ROUGE_hi_en)\n",
    "print(\"BLEU, ROUGE scores of hi_gu\", BLEU_hi_gu, ROUGE_hi_gu)\n",
    "print(\"BLEU, ROUGE scores of gu_hi\", BLEU_gu_hi, ROUGE_gu_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tdVBz-hn-GkE"
   },
   "outputs": [],
   "source": [
    "def save_list_to_file(lst, filename):\n",
    "    with open(f'{filename}.txt', 'w') as f:\n",
    "        for item in lst:\n",
    "            f.write(f'{item}\\n')\n",
    "\n",
    "save_list_to_file(en_hi, 'en_hi')\n",
    "save_list_to_file(hi_en, 'hi_en')\n",
    "save_list_to_file(hi_gu, 'hi_gu')\n",
    "save_list_to_file(gu_hi, 'gu_hi')\n",
    "save_list_to_file(hi, 'hi')\n",
    "save_list_to_file(gu, 'gu')\n",
    "save_list_to_file(en, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ILJjtim_pc3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
